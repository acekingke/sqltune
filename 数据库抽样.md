# **数据库抽样**

抽样方法是从一组数据总体中抽取一部分数据，观察这部分数据的特性，较大概率的得出总体数据特性的方法。数据库中的表查询进行优化时候，需要使用选择性比较好的索引，用以减少查询代价。

 ## 1.抽样的意义与难点

### 抽样的意义

通常，数据库查询会携带where条件从表中选取符合条件的结果。最简单的方式读取所有记录(全表扫描)再过滤，这样做往往会在数据量大的表中选取少量记录，代价非常大。通常数据库会采用索引，尽量减少与条件不符的记录的读取。

使用不同的索引,选取无关记录的数量也是不一样的。比如`select * from people where age = 19 and sex = 'female'` ，显然，如果使用sex列作为索引和选用age做索引效果不一样。一般情况下，男女比例相差不大，而年龄差距不大。所以，以age做索引，age列重复值比较少，选取无关的数据也会比较少。而性别只有两种，重复值比较多，选取无关数据就会比较多。因此，使用age列的索引代价小与使用sex做的索引，这就是列的选择性问题。

通常简单的方式检查列的选择性是

 `select count(distinct(age))/count(age) from people`

 这种选择性检查，有两大弊病，一是全表扫描，代价很大，而是也不正确。同一个列，它值域不见得是均匀分布的，在某个值范围选择性不好，而在另一个值范围选择性可能会很好。比如，以某高校计算机系大一学生为例

`select * from student where age = 19 and sex = 'female'  ` 

有可能一个系中大部分的学生都是19岁，大部分是男生而女生仅仅几个人，这时候，使用sex作为索引，往往优于age作为索引。

以oracle，postgre为代表主流数据库采用数据抽样，生成直方图方式来估算出近似的索引选择性，从而指导查询的索引选择。然而，不幸的是，数据库表中的数据往往以某种形式组织的，具有一定规律性而不是随机的，采用简单的方式抽样，比如，抽取前一千条，或者隔一固定的距离抽样，得到的结果只是一个局部的分布，与总体分布特性相差甚远，可能错误指导查询， 不能指望数据库数据分布随机，因此要保证抽样方式随机。

### 抽样的难点

数据库抽样生成直方图有如下几个难点：

1. **抽样的样本数据要反映总体值域特点**

   达到这个要求，抽样方式必须要足够随机。简单抽取前一千条，或者隔固定的距离抽样不可取。



2. **抽样代价要小**

   抽样算法目前有蓄水池抽样方法，而且目前有性能很好的抽样算法，参见[Jeffrey Vitter](https://en.wikipedia.org/wiki/Jeffrey_Vitter)的研究。postgre数据库采用的就是蓄水池抽样算法。

   目前数据库进行一次抽样生成直方图(执行表统计)，基本上会锁表，数据量很大，执行的时间也会很长，目前并没有科学的办法解决这个问题，数据库管理员(DBA)只能艺术的挑选一个时间点手动执行表统计(实际上在做抽样动作)

3. **数据库的数据集是随时间变化的**

   运行数据库的表会有很多增删改查动作，这导致抽样的样本空间发生变化，最坏的情况是生成的直方图值域分布和实际完全不一致，错误指导查询。

   目前几乎所有数据库采用的方式，只能重新执行一次抽样，再次增加抽样的代价。

 本文的工作

本文并没有解决抽样难点之2，而是在难点3上做一些探讨，得出一种方法，在数据库数据集变化的时候，可以依据历史抽样信息，避免重新执行再次抽样，优化抽样代价。在数据量增长时，要满足难点1，本文也提出了一种代价比重新抽样小的拓展方法，兼顾难点1和难点2，参见第5节.

## **2.蓄水池抽样**

蓄水池抽样用于数据流很大或者数据量不断增长的抽样算法,虽然数据库的表做一次统计,数据量是固定的，但是大部分的数据库系统抽样是逐个数据页抽样，看起来也像是数据量不断增长的样子，一般也用蓄水池抽样的方法。

假设有n个数据，取出k个数据，概率为$$\frac{k \choose 1}{n \choose 1}$$ = $$\frac{k}{n}$$,  如下图所示 。                                                                                      

         +-------------------+               
         | R1,R2......Rk     |        抽样结果(蓄水池)      
         +-----------.-------+               
                     |                       
                     |                       
         +-----------\------------+          
         |  S1,S2...........Sn    | S(n+1)   样本空间 
         +------------------------+          
                              图 1
如果新增一个数据S(n+1)到样本空间。S(n+1)项进入蓄水池的概率为$$\frac{k}{n+1}$$,  以$$\frac{1}{k}$$的概率替换蓄水池中某个元素。那么R1~Rk中某个元素保留在蓄水池的概率为$$P(R1:Rk)=P(R1:Rk样本空间大小为n时进入蓄水池)(P(第n+1个不进入蓄水池) + P(第n+1个进入蓄水池且不替换该元素)) $$

= $$\frac{k}{n} (1-\frac{k}{n+1} +\frac{k}{n+1}\frac{k-1}{k}) = \frac{k}{n}(\frac{n}{n+1}) = \frac{k}{n+1}$$ 

也可以认为,n个元素下R1~Rk是两次抽样，第一次是从n+1个元素选出n个元素，再在n个元素中抽出k个元素。

抽样算法[^1]

```
(*
  S has items to sample, R will contain the result
 *)
ReservoirSample(S[1..n], R[1..k])
  // fill the reservoir array
  for i = 1 to k
      R[i] := S[i]

  // replace elements with gradually decreasing probability
  for i = k+1 to n
    j := random(1, i)   // important: inclusive range
    if j <= k
        R[j] := S[i]
```

当然蓄水池抽样有很多优化方法，参见 [Jeffrey Vitter](https://en.wikipedia.org/wiki/Jeffrey_Vitter) 的算法R~Z等

## 3.删除一个元素

1. 现在反过来，如果S1~S(n+1)中删除掉S(n+1), 那么有两种情况。

* R1~Rk中不存在S(n+1)

  参见上一节图1，可知，S1~Sn的样本空间中新增S(n+1)元素，R1~Rk并没有发生替换，因此R1~Rk本身就是S1~Sn样本空间的一个符合$$\frac{k}{n}$$概率的抽样。

* R1~Rk中存在一个元素Rj = S(n+1)

  同样参见上节图1，如果Rj=S(n+1)， 则表明样本空间S从n增长到n+1时，S(n+1)替换Rj。这时候，只需要重新从S1~Sn的样本中选取概率符合$$\frac{k}{n}$$的样本替换就可以。

2. 现在是否有一个疑问，如果删除的元素不是S(n+1), 而是S1~S(n+1) 之间的元素Sk , 1<= k <n+1，结果如何呢？
我们可以把Sk与S(n+1) 交换，结果和1讨论的情况相同。而**交换样本空间的任意两个元素，并不影响一个抽样的概率** ， 所以，我们仍然可以放心使用1讨论那种情况的算法

算法：

```
(*
  S has items to sample, R will contain the result, d is delete item index
 *)
DeleteSample(S(1..n+1), R[1..k],  d)
   if S[d] not in R[d]
	 return R
   if S[d] in R[d]
   	   // i is the index of find S[d] in result
   	   i = find(R, S[d])
   	   // pick from S except S[d]
   	   R[i] = random_pick_except (S, d)
   	   return R

```



## 4.拓展蓄水池

现在还有一个问题，已知S1~Sn的k样本的抽样，R1~Rk,如何快速构造一个2k的个元素抽样呢

一种方法是重新在S1~Sn的样本抽出2k个样本，R‘1~R'2k，但这种方法几乎是重新做了一遍，并不是一个好办法。

其实，我们只要保证抽样的结果符合概率$\frac{2k}{n}$ 就可以了。

**定理** ：从n个元素样本抽出k个元素，组成符合$\frac{k}{n}$概率的样本R1~Rk，复制到R'1~R’2k ,必定也符合$\frac{2k}{n}$的概率



      +----------------+                                        
      | R1,R2....Rk    |                 k                       
      +----------------+                                        
                                                                
      +-------------------------------+                         
      |     R'1,R'2......R'2k         |         2k               
      +-------------------------------+                         
                                                                
      +--------------------------------------------------------+
      |      S1,S2...Sn                                        | n
      +--------------------------------------------------------+
证明：将S1~Sn到R1~Rk的抽样分成两个步骤。

1) S1~Sn随机抽样到R‘1~R'2k， 那么R‘中从S的每个元素抽取的概率为$P(S\rightarrow R') = \frac{2k}{n}$

2) R'1~R'2k抽样到R1~Rk， R中从R‘的每个元素抽取的概率为$P(R'\rightarrow R) = \frac{k}{2k} = \frac{1}{2}$

3) 综合1) 2) 得出$P(S\rightarrow R) =  P(S\rightarrow R') *P(R'\rightarrow R) = \frac{k}{n}$

而R1~Rk是从R'1~R'2k中抽取出来的，因此R1~Rk均在R'1~R'2k， 因此R1~Rk符合$\frac{k}{n}$,全复制到R'1~R'2k也都是符合$\frac{2k}{n}$的概率

依据定理1,我们可以得到算法

```
(*
  S has items to sample, R will contain the result, R2 is 2k elements result
 *)
ExtendSample(S(1..n), R[1..k],  R2[1..2k])
   copy R[1..k] to R2[1..k]
   Rest_S = remove R[1..k] from S
   R2[k+1..2k] = ReservoirSample(Rest_S,  R2[k+1..2k])
```

## 5.总结

1. 以上删除方式的抽样和拓展样本的抽样的算法，涉及到从序列排除另一个序列元素的操作， 这些操作效率并不高，但是可以采用多次循环抽样再跳过已抽样元素的方式优化，这里不在赘述。
2. 数据库中更新某一行的值，并不改变已经抽样的样本的概率，因此，如果该行已经被抽样，直接更新抽样元素的值即可。
3. 插入一行，可以继续采用蓄水池抽样算法。
4. 建议数据库抽样算法与复制工具结合在一起，降低抽样对数据库系统的性能影响。


[^1]: https://en.wikipedia.org/wiki/Reservoir_sampling